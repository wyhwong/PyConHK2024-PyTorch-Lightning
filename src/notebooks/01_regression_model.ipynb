{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook: Comparison of Native PyTorch Training and PyTorch Lightning\n",
    "\n",
    "This notebook is for comparing how training is implemented in Native PyTorch and PyTorch Lightning. The aim of the notebook is to show what PyTorch Lightning does under the hood and how it simplifies the training process. The notebook contains the following sections:\n",
    "- Generate Data: Generate a simple dataset for training\n",
    "- Native PyTorch Training: Implement training in Native PyTorch\n",
    "- PyTorch Lightning Training: Implement training in PyTorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "import demo.lightning.models\n",
    "import demo.torch.models\n",
    "from demo.torch.utils import get_optimizer, get_scheduler, train_regression_model\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data: Generate a simple dataset for training\n",
    "\n",
    "In this section, we generate a simple dataset for training. The dataset is generated using a linear function x=y with some noise. The dataset contains 500 samples with just one feature and one target. Since the objective here is to demonstrate the difference between Native PyTorch and PyTorch Lightning, a simple dataset is sufficient and will serve the purpose better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(x, y, y_pred=None):\n",
    "    \"\"\"Scatter plot of the data points and the predictions\"\"\"\n",
    "\n",
    "    _, ax = plt.subplots(figsize=(6, 6))\n",
    "    sns.scatterplot(x=x.flatten(), y=y.flatten(), label=\"Observations\", ax=ax)\n",
    "    sns.lineplot(\n",
    "        x=x.flatten(), y=x.flatten(), linestyle=\"--\", color=\"red\", label=\"Ground truth\"\n",
    "    )\n",
    "    if y_pred is not None:\n",
    "        sns.scatterplot(\n",
    "            x=x.flatten(), y=y_pred.flatten(), color=\"green\", label=\"Predictions\"\n",
    "        )\n",
    "    ax.set(xlabel=\"X\", ylabel=\"Y\", title=\"Simple linear regression dataset\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a very simple dataset for linear regression\n",
    "x = torch.linspace(0, 1, 500).view(-1, 1)\n",
    "y = x + 0.2 * torch.randn_like(x)\n",
    "\n",
    "visualize(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Native PyTorch Training: Implement training in Native PyTorch\n",
    "\n",
    "In this section, we implement the training process in Native PyTorch. The training process includes the following steps:\n",
    "- Define the model.\n",
    "- Define the loss function.\n",
    "- Define the optimizer.\n",
    "- Define the scheduler.\n",
    "- Define the dataloaders.\n",
    "- Define the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = demo.torch.models.LinearRegression(in_features=1, out_features=1)\n",
    "loss_fn = torch.nn.functional.mse_loss\n",
    "optimizer = get_optimizer(torch_model)\n",
    "scheduler = get_scheduler(optimizer)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(x, y), batch_size=16, shuffle=True\n",
    ")\n",
    "# While in practice we use a different dataset for validation, here we use the same for simplicity\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(x, y), batch_size=16, shuffle=False\n",
    ")\n",
    "\n",
    "train_regression_model(\n",
    "    model=torch_model,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    n_epochs=5,\n",
    "    device=torch.device(\"cuda\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = torch_model(x.to(\"cuda\")).detach().cpu()\n",
    "\n",
    "visualize(x, y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Lightning Training: Implement training in PyTorch Lightning\n",
    "\n",
    "In this section, we implement the training process in PyTorch Lightning. The training process includes the following steps:\n",
    "- Define a lightning module\n",
    "- Define a lightning data module\n",
    "- Define a pytorch lightning trainer\n",
    "- Run the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(lightning.LightningDataModule):\n",
    "    \"\"\" PyTorch Lightning data module \"\"\"\n",
    "\n",
    "    def __init__(self, x: torch.tensor, y: torch.tensor, batch_size: int):\n",
    "        \"\"\" Data module for the simple linear regression dataset \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.train_dataset = torch.utils.data.TensorDataset(x, y)\n",
    "        self.val_dataset = torch.utils.data.TensorDataset(x, y)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        \"\"\" Training data loader \"\"\"\n",
    "\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset, batch_size=self.batch_size, shuffle=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        \"\"\" Validation data loader \"\"\"\n",
    "\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset, batch_size=self.batch_size, shuffle=False\n",
    "        )\n",
    "\n",
    "lightning.pytorch.seed_everything(42, workers=True)\n",
    "\n",
    "lightning_model = demo.lightning.models.LinearRegression(in_features=1, out_features=1)\n",
    "data_module = DataModule(x, y, batch_size=16)\n",
    "trainer = lightning.pytorch.Trainer(max_epochs=5, log_every_n_steps=1)\n",
    "\n",
    "trainer.fit(model=lightning_model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lightning_model(x).detach().cpu()\n",
    "\n",
    "visualize(x, y, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
